# Bayesian Inference (BI)

In this lesson we will use the infamous Phylobayes [(Lartillot et al., 2013)](https://doi.org/10.1093/sysbio/syt022) to understand the underlying principles of Bayesian Inference in phylogenetics. Remember that in a Bayesian framework we estimate parameters from their posterior distribution, instead of finding the best single estimates as in a Maximum Likelihood framework.

---

### MSA format conversion: 

At this stage we have already used ```.fas``` and ```.nxs``` formats. In this lesson we will also need a ```.phy``` - a phylip-formatted file. This format name comes from a very ancient piece of software - called of course [PHYLIP](https://en.wikipedia.org/wiki/PHYLIP) - which is over 40 years old! You can do it quickly using:

```
AMAS.py convert -d dna -u nexus -f fasta -i data/example_alignements/Rhabdomeric1.nt.aln
```

---

### Bayesian Inference: 

Having a ```.phy``` alignement we can quickly lunch the BI inference ... twice! The reason for that is that we will need to asses the convergence of the two chains, as you should have learned from the practicals! So:

```
 mpirun -np 2 pb_mpi -d Rhabdomeric1.nt.aln-out.phy chain1
```

and 

```
 mpirun -np 2 pb_mpi -d Rhabdomeric1.nt.aln-out.phy chain2
```

... and then take a looong break, just bcause BI is very computationally intensive, even on such small datasets!

---

### post-inference diagnostics

We can _kill_ the two processes by just pressing ``` ctrl + C```. Then take a look to what happened during the break:
 
* ```.chain```
* ```.monitor```
* ```.param```
* ```.run```
* ```.trace```
* ```.treelist```

A nice way to carry out this post-inference diagnostics (that is often done during the inference) is Tracer,
which offers an easy way to explore what's going on in our inference.

In Tracer we want to see the famous __fuzzy caterpillar__ - by far the most loved animals by phylogeneticists -
which implies that there's no autocorrelation in our analysis and that it has reached stationarity. You can 
take a look  in Tracer at an [awful](https://github.com/for-giobbe/phy/raw/master/examples/bad_trace_example.p) 
and [cool](https://github.com/for-giobbe/phy/raw/master/examples/good_trace_example.p) sampling coming fromt two
distinct runs, to get a sense of how much they can be different.

---

### consensus tree

Now let's open our consensus tree and take a look at it! (it will be terrible, you are advised ..)


> Probably in many of your trees you will see politomies (*i.e* more than two branches descending from a single node). Remember that MrBayes, as all ML approaches, doesn't produce multifurcating trees during the run! When we have used the ```sumt``` command we have also sumarized all sampled trees in a consensus one (after burn-in discarding). While doing this it has calculated the Posterior Probabilities of each node/bipartition (*i.e* The proportion of the time that the bipartition is found in the sampled trees). If the posterior probability of a node was below the default cutoff of 0.5, mb by default collapsed that branch in a politomy.

---

### [main](https://github.com/for-giobbe/MP25/tree/main)